{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "422f7f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blue ROI saved: output\\blue_roi_1.jpg\n",
      "Predicted Size: -0.01 mm\n",
      "Predicted Thickness: 0.21 mm\n",
      "Blue ROI saved: output\\blue_roi_10.jpg\n",
      "Predicted Size: 0.15 mm\n",
      "Predicted Thickness: 0.00 mm\n",
      "Blue ROI saved: output\\blue_roi_11.jpg\n",
      "Predicted Size: -0.12 mm\n",
      "Predicted Thickness: 0.12 mm\n",
      "Blue ROI saved: output\\blue_roi_12.jpg\n",
      "Predicted Size: -0.03 mm\n",
      "Predicted Thickness: 0.04 mm\n",
      "Blue ROI saved: output\\blue_roi_13.jpg\n",
      "Predicted Size: -0.02 mm\n",
      "Predicted Thickness: 0.08 mm\n",
      "Blue ROI saved: output\\blue_roi_14.jpg\n",
      "Predicted Size: 0.18 mm\n",
      "Predicted Thickness: 0.05 mm\n",
      "Blue ROI saved: output\\blue_roi_15.jpg\n",
      "Predicted Size: 0.29 mm\n",
      "Predicted Thickness: -0.18 mm\n",
      "Blue ROI saved: output\\blue_roi_16.jpg\n",
      "Predicted Size: 0.14 mm\n",
      "Predicted Thickness: -0.21 mm\n",
      "Blue ROI saved: output\\blue_roi_17.jpg\n",
      "Predicted Size: 0.02 mm\n",
      "Predicted Thickness: 0.21 mm\n",
      "Blue ROI saved: output\\blue_roi_18.jpg\n",
      "Predicted Size: 0.02 mm\n",
      "Predicted Thickness: -0.05 mm\n",
      "Blue ROI saved: output\\blue_roi_19.jpg\n",
      "Predicted Size: -0.07 mm\n",
      "Predicted Thickness: -0.06 mm\n",
      "Blue ROI saved: output\\blue_roi_2.jpg\n",
      "Predicted Size: 0.01 mm\n",
      "Predicted Thickness: 0.16 mm\n",
      "Blue ROI saved: output\\blue_roi_20.jpg\n",
      "Predicted Size: -0.01 mm\n",
      "Predicted Thickness: -0.03 mm\n",
      "Blue ROI saved: output\\blue_roi_21.jpg\n",
      "Predicted Size: 0.14 mm\n",
      "Predicted Thickness: 0.13 mm\n",
      "Blue ROI saved: output\\blue_roi_22.jpg\n",
      "Predicted Size: 0.16 mm\n",
      "Predicted Thickness: 0.06 mm\n",
      "Blue ROI saved: output\\blue_roi_23.jpg\n",
      "Predicted Size: 0.06 mm\n",
      "Predicted Thickness: -0.03 mm\n",
      "Blue ROI saved: output\\blue_roi_24.jpg\n",
      "Predicted Size: 0.01 mm\n",
      "Predicted Thickness: -0.09 mm\n",
      "Blue ROI saved: output\\blue_roi_25.jpg\n",
      "Predicted Size: -0.04 mm\n",
      "Predicted Thickness: -0.12 mm\n",
      "Blue ROI saved: output\\blue_roi_26.jpg\n",
      "Predicted Size: -0.06 mm\n",
      "Predicted Thickness: 0.08 mm\n",
      "Blue ROI saved: output\\blue_roi_27.jpg\n",
      "Predicted Size: 0.07 mm\n",
      "Predicted Thickness: -0.12 mm\n",
      "Blue ROI saved: output\\blue_roi_28.jpg\n",
      "Predicted Size: 0.16 mm\n",
      "Predicted Thickness: 0.27 mm\n",
      "Blue ROI saved: output\\blue_roi_29.jpg\n",
      "Predicted Size: 0.18 mm\n",
      "Predicted Thickness: 0.04 mm\n",
      "Blue ROI saved: output\\blue_roi_3.jpg\n",
      "Predicted Size: 0.04 mm\n",
      "Predicted Thickness: -0.08 mm\n",
      "Blue ROI saved: output\\blue_roi_30.jpg\n",
      "Predicted Size: 0.02 mm\n",
      "Predicted Thickness: 0.04 mm\n",
      "Blue ROI saved: output\\blue_roi_31.jpg\n",
      "Predicted Size: -0.09 mm\n",
      "Predicted Thickness: -0.05 mm\n",
      "Blue ROI saved: output\\blue_roi_32.jpg\n",
      "Predicted Size: 0.24 mm\n",
      "Predicted Thickness: 0.09 mm\n",
      "Blue ROI saved: output\\blue_roi_33.jpg\n",
      "Predicted Size: 0.06 mm\n",
      "Predicted Thickness: 0.02 mm\n",
      "Blue ROI saved: output\\blue_roi_34.jpg\n",
      "Predicted Size: 0.11 mm\n",
      "Predicted Thickness: 0.22 mm\n",
      "Blue ROI saved: output\\blue_roi_4.jpg\n",
      "Predicted Size: -0.03 mm\n",
      "Predicted Thickness: 0.05 mm\n",
      "Blue ROI saved: output\\blue_roi_5.jpg\n",
      "Predicted Size: 0.10 mm\n",
      "Predicted Thickness: -0.02 mm\n",
      "Blue ROI saved: output\\blue_roi_6.jpg\n",
      "Predicted Size: 0.05 mm\n",
      "Predicted Thickness: -0.18 mm\n",
      "Blue ROI saved: output\\blue_roi_7.jpg\n",
      "Predicted Size: 0.23 mm\n",
      "Predicted Thickness: 0.09 mm\n",
      "Blue ROI saved: output\\blue_roi_8.jpg\n",
      "Predicted Size: -0.02 mm\n",
      "Predicted Thickness: 0.01 mm\n",
      "Blue ROI saved: output\\blue_roi_9.jpg\n",
      "Predicted Size: -0.03 mm\n",
      "Predicted Thickness: -0.25 mm\n"
     ]
    }
   ],
   "source": [
    "#multiple images\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image, ImageOps\n",
    "import glob\n",
    "import random\n",
    "\n",
    "# === Input and output folder setup ===\n",
    "input_folder = \"images\"\n",
    "warm_crop_folder = \"roi_images\"\n",
    "blue_roi_folder = \"output\"\n",
    "\n",
    "os.makedirs(warm_crop_folder, exist_ok=True)\n",
    "os.makedirs(blue_roi_folder, exist_ok=True)\n",
    "\n",
    "# Supported image extensions\n",
    "image_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff')\n",
    "\n",
    "# CNN Model for Defect Prediction from Images\n",
    "class DefectPredictionCNN(nn.Module):\n",
    "    def __init__(self):  # <-- Correct constructor\n",
    "        super(DefectPredictionCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        self.flattened_size = self._get_flattened_size()\n",
    "        self.fc1 = nn.Linear(self.flattened_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 2)  # Predict size and thickness\n",
    "\n",
    "    def _get_flattened_size(self):\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, 3, 224, 224)\n",
    "            x = self.pool1(F.relu(self.conv1(dummy_input)))\n",
    "            x = self.pool2(F.relu(self.conv2(x)))\n",
    "            x = self.pool3(F.relu(self.conv3(x)))\n",
    "            return x.view(1, -1).size(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Function to preprocess images\n",
    "def preprocess_image(image_path, target_size=(224, 224)):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    original_size = image.size\n",
    "    image = ImageOps.pad(image, target_size, method=Image.Resampling.LANCZOS, color=(0, 0, 0))\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "    return transform(image).unsqueeze(0), original_size\n",
    "\n",
    "# Load Model\n",
    "model = DefectPredictionCNN()\n",
    "model.eval()\n",
    "\n",
    "# === Image Processing and Prediction ===\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.lower().endswith(image_extensions):\n",
    "        img_path = os.path.join(input_folder, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"Couldn't load: {filename}\")\n",
    "            continue\n",
    "\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        # Step 1: Warm region (yellow-green ~28Â°C)\n",
    "        lower_warm = np.array([25, 100, 100])\n",
    "        upper_warm = np.array([40, 255, 255])\n",
    "        warm_mask = cv2.inRange(hsv, lower_warm, upper_warm)\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "        warm_mask = cv2.morphologyEx(warm_mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "        contours, _ = cv2.findContours(warm_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        if contours:\n",
    "            largest = max(contours, key=cv2.contourArea)\n",
    "            x, y, w, h = cv2.boundingRect(largest)\n",
    "            warm_roi = img[y:y+h, x:x+w]\n",
    "            hsv_roi = hsv[y:y+h, x:x+w]\n",
    "\n",
    "            warm_path = os.path.join(warm_crop_folder, f\"warm_crop_{filename}\")\n",
    "            cv2.imwrite(warm_path, warm_roi)\n",
    "\n",
    "            lower_blue = np.array([100, 50, 50])\n",
    "            upper_blue = np.array([130, 255, 255])\n",
    "            blue_mask = cv2.inRange(hsv_roi, lower_blue, upper_blue)\n",
    "            blue_mask = cv2.morphologyEx(blue_mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "            blue_contours, _ = cv2.findContours(blue_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            if blue_contours:\n",
    "                blue_largest = max(blue_contours, key=cv2.contourArea)\n",
    "                bx, by, bw, bh = cv2.boundingRect(blue_largest)\n",
    "                blue_roi = warm_roi[by:by+bh, bx:bx+bw]\n",
    "\n",
    "                blue_path = os.path.join(blue_roi_folder, f\"blue_roi_{filename}\")\n",
    "                cv2.imwrite(blue_path, blue_roi)\n",
    "\n",
    "                # Predict using CNN\n",
    "                image_tensor, original_size = preprocess_image(blue_path)\n",
    "                with torch.no_grad():\n",
    "                    prediction = model(image_tensor)\n",
    "\n",
    "                # Add randomness to simulate variation (optional)\n",
    "                noise = torch.randn_like(prediction) * 0.1\n",
    "                prediction += noise\n",
    "\n",
    "                size, thickness = prediction[0].tolist()\n",
    "\n",
    "                print(f\"Blue ROI saved: {blue_path}\")\n",
    "                print(f\"Predicted Size: {size:.2f} mm\")\n",
    "                print(f\"Predicted Thickness: {thickness:.2f} mm\")\n",
    "            else:\n",
    "                print(f\"No blue region found inside warm area in {filename}\")\n",
    "        else:\n",
    "            print(f\"No warm (yellow) region found in {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc57fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
