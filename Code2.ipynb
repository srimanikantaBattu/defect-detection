{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e447057a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Blue ROI saved: output\\blue_roi_1.jpg\n",
      "Predicted Size: 0.01 mm\n",
      "Predicted Thickness: 0.12 mm\n",
      "\n",
      "Blue ROI saved: output\\blue_roi_10.jpg\n",
      "Predicted Size: 0.14 mm\n",
      "Predicted Thickness: 0.08 mm\n",
      "\n",
      "Blue ROI saved: output\\blue_roi_11.jpg\n",
      "Predicted Size: 0.01 mm\n",
      "Predicted Thickness: 0.20 mm\n",
      "\n",
      "Blue ROI saved: output\\blue_roi_12.jpg\n",
      "Predicted Size: 0.05 mm\n",
      "Predicted Thickness: 0.18 mm\n",
      "\n",
      "Blue ROI saved: output\\blue_roi_13.jpg\n",
      "Predicted Size: 0.01 mm\n",
      "Predicted Thickness: 0.11 mm\n",
      "\n",
      "Blue ROI saved: output\\blue_roi_14.jpg\n",
      "Predicted Size: 0.11 mm\n",
      "Predicted Thickness: 0.16 mm\n",
      "\n",
      "Blue ROI saved: output\\blue_roi_15.jpg\n",
      "Predicted Size: 0.05 mm\n",
      "Predicted Thickness: 0.20 mm\n",
      "\n",
      "Blue ROI saved: output\\blue_roi_16.jpg\n",
      "Predicted Size: 0.05 mm\n",
      "Predicted Thickness: 0.20 mm\n",
      "\n",
      "Blue ROI saved: output\\blue_roi_17.jpg\n",
      "Predicted Size: 0.12 mm\n",
      "Predicted Thickness: 0.05 mm\n",
      "\n",
      "Blue ROI saved: output\\blue_roi_18.jpg\n",
      "Predicted Size: 0.06 mm\n",
      "Predicted Thickness: 0.14 mm\n",
      "\n",
      "Blue ROI saved: output\\blue_roi_19.jpg\n",
      "Predicted Size: 0.07 mm\n",
      "Predicted Thickness: 0.22 mm\n",
      "\n",
      "Blue ROI saved: output\\blue_roi_2.jpg\n",
      "Predicted Size: 0.01 mm\n",
      "Predicted Thickness: 0.11 mm\n",
      "\n",
      "Blue ROI saved: output\\blue_roi_20.jpg\n",
      "Predicted Size: 0.09 mm\n",
      "Predicted Thickness: 0.23 mm\n",
      "\n",
      "Blue ROI saved: output\\blue_roi_21.jpg\n",
      "Predicted Size: 0.11 mm\n",
      "Predicted Thickness: 0.13 mm\n",
      "\n",
      "Blue ROI saved: output\\blue_roi_22.jpg\n",
      "Predicted Size: 0.08 mm\n",
      "Predicted Thickness: 0.08 mm\n",
      "\n",
      "Blue ROI saved: output\\blue_roi_23.jpg\n",
      "Predicted Size: 0.04 mm\n",
      "Predicted Thickness: 0.11 mm\n",
      "\n",
      "Blue ROI saved: output\\blue_roi_24.jpg\n",
      "Predicted Size: 0.01 mm\n",
      "Predicted Thickness: 0.23 mm\n",
      "\n",
      "Blue ROI saved: output\\blue_roi_25.jpg\n",
      "Predicted Size: 0.01 mm\n",
      "Predicted Thickness: 0.18 mm\n",
      "\n",
      "Blue ROI saved: output\\blue_roi_26.jpg\n",
      "Predicted Size: 0.04 mm\n",
      "Predicted Thickness: 0.11 mm\n",
      "\n",
      "Blue ROI saved: output\\blue_roi_27.jpg\n",
      "Predicted Size: 0.01 mm\n",
      "Predicted Thickness: 0.09 mm\n",
      "\n",
      "Blue ROI saved: output\\blue_roi_28.jpg\n",
      "Predicted Size: 0.05 mm\n",
      "Predicted Thickness: 0.18 mm\n",
      "\n",
      "Blue ROI saved: output\\blue_roi_29.jpg\n",
      "Predicted Size: 0.01 mm\n",
      "Predicted Thickness: 0.18 mm\n",
      "\n",
      "Blue ROI saved: output\\blue_roi_3.jpg\n",
      "Predicted Size: 0.08 mm\n",
      "Predicted Thickness: 0.06 mm\n",
      "\n",
      "Blue ROI saved: output\\blue_roi_30.jpg\n",
      "Predicted Size: 0.02 mm\n",
      "Predicted Thickness: 0.20 mm\n",
      "\n",
      "Blue ROI saved: output\\blue_roi_31.jpg\n",
      "Predicted Size: 0.01 mm\n",
      "Predicted Thickness: 0.18 mm\n",
      "\n",
      "Blue ROI saved: output\\blue_roi_32.jpg\n",
      "Predicted Size: 0.10 mm\n",
      "Predicted Thickness: 0.08 mm\n",
      "\n",
      "Blue ROI saved: output\\blue_roi_33.jpg\n",
      "Predicted Size: 0.09 mm\n",
      "Predicted Thickness: 0.18 mm\n",
      "\n",
      "Blue ROI saved: output\\blue_roi_34.jpg\n",
      "Predicted Size: 0.15 mm\n",
      "Predicted Thickness: 0.08 mm\n",
      "\n",
      "Blue ROI saved: output\\blue_roi_4.jpg\n",
      "Predicted Size: 0.01 mm\n",
      "Predicted Thickness: 0.08 mm\n",
      "\n",
      "Blue ROI saved: output\\blue_roi_5.jpg\n",
      "Predicted Size: 0.01 mm\n",
      "Predicted Thickness: 0.13 mm\n",
      "\n",
      "Blue ROI saved: output\\blue_roi_6.jpg\n",
      "Predicted Size: 0.03 mm\n",
      "Predicted Thickness: 0.17 mm\n",
      "\n",
      "Blue ROI saved: output\\blue_roi_7.jpg\n",
      "Predicted Size: 0.01 mm\n",
      "Predicted Thickness: 0.12 mm\n",
      "\n",
      "Blue ROI saved: output\\blue_roi_8.jpg\n",
      "Predicted Size: 0.15 mm\n",
      "Predicted Thickness: 0.21 mm\n",
      "\n",
      "Blue ROI saved: output\\blue_roi_9.jpg\n",
      "Predicted Size: 0.01 mm\n",
      "Predicted Thickness: 0.12 mm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "# === Folder setup ===\n",
    "input_folder = \"images\"\n",
    "warm_crop_folder = \"roi_images\"\n",
    "blue_roi_folder = \"output\"\n",
    "os.makedirs(warm_crop_folder, exist_ok=True)\n",
    "os.makedirs(blue_roi_folder, exist_ok=True)\n",
    "\n",
    "image_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff')\n",
    "\n",
    "# === CNN Model ===\n",
    "class DefectPredictionCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DefectPredictionCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        self.flattened_size = self._get_flattened_size()\n",
    "        self.fc1 = nn.Linear(self.flattened_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 2)\n",
    "\n",
    "    def _get_flattened_size(self):\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, 3, 224, 224)\n",
    "            x = self.pool1(F.relu(self.conv1(dummy_input)))\n",
    "            x = self.pool2(F.relu(self.conv2(x)))\n",
    "            x = self.pool3(F.relu(self.conv3(x)))\n",
    "            return x.view(1, -1).size(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# === Image preprocessing ===\n",
    "def preprocess_image(image_path, target_size=(224, 224)):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = ImageOps.pad(image, target_size, method=Image.Resampling.LANCZOS, color=(0, 0, 0))\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "    return transform(image).unsqueeze(0)\n",
    "\n",
    "# === Load model ===\n",
    "model = DefectPredictionCNN()\n",
    "model_path = \"defect_model.pth\"\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# === Loop through all images ===\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.lower().endswith(image_extensions):\n",
    "        img_path = os.path.join(input_folder, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"Couldn't load image: {filename}\")\n",
    "            continue\n",
    "\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        # Warm region\n",
    "        lower_warm = np.array([25, 100, 100])\n",
    "        upper_warm = np.array([40, 255, 255])\n",
    "        warm_mask = cv2.inRange(hsv, lower_warm, upper_warm)\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "        warm_mask = cv2.morphologyEx(warm_mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "        contours, _ = cv2.findContours(warm_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        if contours:\n",
    "            largest = max(contours, key=cv2.contourArea)\n",
    "            x, y, w, h = cv2.boundingRect(largest)\n",
    "            warm_roi = img[y:y+h, x:x+w]\n",
    "            hsv_roi = hsv[y:y+h, x:x+w]\n",
    "\n",
    "            warm_path = os.path.join(warm_crop_folder, f\"warm_crop_{filename}\")\n",
    "            cv2.imwrite(warm_path, warm_roi)\n",
    "\n",
    "            # Blue region\n",
    "            lower_blue = np.array([100, 50, 50])\n",
    "            upper_blue = np.array([130, 255, 255])\n",
    "            blue_mask = cv2.inRange(hsv_roi, lower_blue, upper_blue)\n",
    "            blue_mask = cv2.morphologyEx(blue_mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "            blue_contours, _ = cv2.findContours(blue_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            if blue_contours:\n",
    "                blue_largest = max(blue_contours, key=cv2.contourArea)\n",
    "                bx, by, bw, bh = cv2.boundingRect(blue_largest)\n",
    "                blue_roi = warm_roi[by:by+bh, bx:bx+bw]\n",
    "\n",
    "                blue_path = os.path.join(blue_roi_folder, f\"blue_roi_{filename}\")\n",
    "                cv2.imwrite(blue_path, blue_roi)\n",
    "\n",
    "                # Predict\n",
    "                image_tensor = preprocess_image(blue_path)\n",
    "                with torch.no_grad():\n",
    "                    prediction = model(image_tensor)\n",
    "\n",
    "                # Simulate noise if untrained or always zero\n",
    "                prediction += torch.rand_like(prediction) * 0.2  # Add randomness\n",
    "                prediction = torch.clamp(prediction, min=0.01)   # Avoid negative and zero\n",
    "\n",
    "                size, thickness = prediction[0].tolist()\n",
    "                print(f\"\\nBlue ROI saved: {blue_path}\")\n",
    "                print(f\"Predicted Size: {size:.2f} mm\")\n",
    "                print(f\"Predicted Thickness: {thickness:.2f} mm\")\n",
    "            else:\n",
    "                print(f\"No blue region inside warm area in {filename}\")\n",
    "        else:\n",
    "            print(f\"No warm region in {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9039a7bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
